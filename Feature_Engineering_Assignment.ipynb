{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mGbuCclOmjek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering Assignment.\n",
        "---\n"
      ],
      "metadata": {
        "id": "geiZh0AHmlqw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.  What is a parameter?\n",
        "  - A Parameter is a constant value used to define a population or Model.\n",
        "      - eg: In Linear regression, the slope and intercept are model parameters.\n",
        "  - In the Feature Engineering context, a parameter is a setting or configuration value used during data transformation or feature construction. Unlike model parameters (like weights), feature engineering parameters define how we manipulate or derive features.\n",
        "      - Eg:  - Binning age into groups\n",
        "            - Parameter: bin edges, e.g. [0, 18, 35, 60, 100]\n",
        "            - Result: transforms age into categories like teen, adult, senior\n",
        "    - These parameters shape the feature space, the model learns from — tuning them carefully can improve both performance and interpretability.\n",
        "\n",
        "2. a & 12.  What is correlation? What does negative correlation mean?\n",
        "  - Correlation measures the strength and direction of a relationship between two variables.\n",
        "      - *eg: Height and weight often have positive correlation.*\n",
        "\n",
        "  2.b & 13. - A **Negative correlation** means one variable increases as the other decreases or vice-versa. (Inverse prorportionality.\n",
        "      - *eg: Study hours vs No. of Failed subjects..*\n",
        "\n",
        "3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "  - **Machine Learning** is the use of algorithms to enable computers to learn patterns from data without explicitly programming.\n",
        "\n",
        "|Main Components|\n",
        "|---------------|\n",
        "|Dataset|\n",
        "|Model|\n",
        "|Loss Function|\n",
        "|Optimizer|\n",
        "|Evaluation Metric|\n",
        "\n",
        "4. How does loss value help in determining whether the model is good or not?\n",
        "  - The loss value quantifies how far off the model's predictions are from the actual outcomes. It's like a penalty score for being wrong.\n",
        "      - Why It Matters:\n",
        "        - A low loss indicates that the model predicts well on the training data.\n",
        "        - A high loss signals poor predictions, suggesting underfitting or bad feature choices.\n",
        "\n",
        "    - Examples:\n",
        "      - Mean Squared Error (MSE) in regression\n",
        "        Measures average squared difference between predicted and actual values.\n",
        "        - MSE = 3.2 → decent\n",
        "        - MSE = 92 → poor fit\n",
        "      - Cross-Entropy Loss in classification\n",
        "        Penalizes confident wrong predictions more harshly.\n",
        "        - Lower value → better class separation\n",
        "\n",
        "      Loss helps during:\n",
        "      - Model training (to guide optimization)\n",
        "      - Comparison of models\n",
        "      - Tuning hyperparameters\n",
        "\n",
        "5. What are continuous and categorical variables?\n",
        "  - Continuous: Numeric values with infinite possibilities (e.g. height).\n",
        "  - Categorical: Values in categories (e.g. color: red, green).\n",
        "\n",
        "6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "  - Label Encoding (Red = 0, Blue = 1)\n",
        "  - One-Hot Encoding (creates binary columns for each category)\n",
        "\n",
        "7. What do you mean by training and testing a dataset?\n",
        "  - Training Set:\n",
        "      - Used to build and teach the model. The algorithm learns patterns, relationships, and feature importance from this data.\n",
        "      - Model sees both input features and target labels.\n",
        "      - It's like the textbook the model studies.\n",
        "\n",
        "  - Testing Set: Used to evaluate the model's performance.\n",
        "      - Used to evaluate the model’s performance on unseen data. This shows how well the model generalizes.\n",
        "      - Model gets only input features and predicts outputs.\n",
        "      - It's like the exam paper after training.\n",
        "\n",
        "   - Helps detect:\n",
        "      - Overfitting: Too good on training, bad on testing.\n",
        "      - Underfitting: Poor performance on both sets\n",
        "\n",
        "    - Eg: Usual Train-Test Split is: Train on 80% data, Test on 20%.\n",
        "\n",
        "8. What is sklearn.preprocessing?\n",
        "  - A module in **scikit-learn** with tools for Data Preprocessing / transforming data before feeding it to the Maching Learning Models.\n",
        "  Includes: scaling, encoding, normalization functions.\n",
        "\n",
        "\n",
        "  |Task|Tool|Purpose|\n",
        "  |:----|:----|:-----|\n",
        "  |Scaling|StandardScaler, MinMaxScaler|Normalize feature ranges|\n",
        "  |Encoding|LabelEncoder, OnHotEncoder|Convert categorical to numerical|\n",
        "  |Polynomial Features|PolynomialFeatures|Add interaction/ Higher-order terms|\n",
        "  |Binarization|Binarizer|Convert numeric to binary|\n",
        "  |Normalization|Normalizer|Scale Individual samples|\n",
        "\n",
        "\n",
        "9. What is a Test set?\n",
        "   - Testing Set: Dataset reserved to evaluate the model's performance after training.\n",
        "      - Used to evaluate the model's performance on unseen data. This shows how well the model generalizes / predicts.\n",
        "      - Model gets only input features and predicts outputs.\n",
        "      - It's like the giving the exam after training.\n",
        "\n",
        "10. How do we split data for model fitting (training and testing) in Python? How do you approach a Machine Learning problem?\n",
        " ```\n",
        " from sklearn.model_selection import train_test_split  \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "#  0.2 - refers to 20% data reserved for testing while 80% for training\n",
        "```\n",
        "          Approach to ML problem:\n",
        "          - EDA\n",
        "          - Preprocessing\n",
        "          - Model selection\n",
        "          - Training\n",
        "          - Evaluation\n",
        "          - Tuning\n",
        "\n",
        "11. Why do we have to perform EDA before fitting a model to the data?\n",
        "  - We perform EDA first:\n",
        "    - To understand data patterns, spot missing values, and uncover biases.\n",
        "      - Example: Detect outliers, skewed distributions before modeling.\n",
        "\n",
        "12. What is correlation? - duplicate\n",
        "  ## - Duplicate, Answered Above -\n",
        "\n",
        "13. What does negative correlation mean? - duplicate\n",
        "  ## - Duplicate, Answered Above -\n",
        "\n",
        "\n",
        "14. How can you find correlation between variables in Python?\n",
        "```\n",
        "df.corr()  # Pandas method to compute correlation matrix\n",
        "```\n",
        "\n",
        "15. What is causation? Explain difference between correlation and causation with an example.\n",
        "  -  Causation: When One variable directly influences another. There's a cause-and-effect relationship.\n",
        "  - Eg: Ice cream sales and sunburns **Correlate** whereas, Hot weather is the **Causation** for both Ice sales & Sun burns and not one another.\n",
        "    - Smoking causes increased risk of lung disease. Here, Smoking is the reason for this health outcome.\n",
        "\n",
        "16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "  - An optimizer is an algorithm that adjusts the model's parameters (like weights and biases) to minimize the loss function during training. It guides the model to better predictions by taking steps in the direction that reduces error.\n",
        "\n",
        "|Optimiser|How it Works|Example Use Case|\n",
        "|:------:|:---:|:-------:|\n",
        "|SGD(Stochastic <br> Gradient Descent)|Updates weights using one random sample <br> at a time. Simple and memory-efficient|Basic Neural networks and linear models|\n",
        "|Momentum|Adds a fraction of the previous update to <br> current step — helps speed up and smooth training.|Deep networks prone to slow convergence|\n",
        "|RMSprop|Adjusts learning rate based  on recent gradients.<br>  Good for non-stationary objectives.|RNNs and time-series problems|\n",
        "|Adam (Adaptive <br> Moment Estimation|Combines Momentum and RMSprop. Automatically adapts <br> learning rate for each parameter.|CNNs, deep learning — fast & stable|\n",
        "\n",
        "  - Adam is often the go-to for deep learning because it balances speed and stability.\n",
        "\n",
        "17. What is sklearn.linear_model ?\n",
        "  - It's a module in scikit-learn that contains models for linear relationships.\n",
        "      - Key Models:\n",
        "      - ```LinearRegression```: Predicts continuous values using a linear equation.\n",
        "      - ```LogisticRegression```: Handles binary/multiclass classification using a logistic function.\n",
        "      - ```Ridge, Lasso```: Regularized versions to prevent overfitting\n",
        "\n",
        "18. What does model.fit() do? What arguments must be given?\n",
        "    -  Fits model to training data.\n",
        "        - Args: X_train, y_train\n",
        "          ```model.fit(X_train, y_train)```\n",
        "          \n",
        "19. What does model.predict() do? What arguments must be given?\n",
        "    - Generates predictions on new data. ```Args: X_test```\n",
        "    - ```model.predict(X_test)```\n",
        "\n",
        "20. What are continuous and categorical variables? - duplicate\n",
        "  ## - Duplicate, Answered Above -\n",
        "\n",
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        "    - Feature scaling is the process of transforming input variables so they're on the same scale, typically between 0-1 or with mean 0 and standard deviation 1.\n",
        "    - Why?\n",
        "      - Many algorithms use distance or gradients — so differing scales can skew results or slow convergence.\n",
        "    - How It Helps in ML\n",
        "      - Speeds Up Training: Gradient-based optimizers converge faster.\n",
        "      - Improves Accuracy: Prevents dominant features from overshadowing others.\n",
        "      - Balances Inputs: Especially important for algorithms like KNN, SVM, or Logistic Regression.\n",
        "  - eg: Imagine features:\n",
        "      - Age: 25-60\n",
        "      - Income: ₹1,00,000 - ₹15,00,000\n",
        "      - Without scaling, income would dominate distance calculations.\n",
        "      - After scaling (e.g. StandardScaler), both get equal weight.\n",
        "\n",
        "22. How do we perform scaling in Python?\n",
        "  - You can perform feature scaling in Python using scikit-learn, the most commonly used library for this task:\n",
        "  - Step-by-Step: Scaling with StandardScaler and MinMaxScaler\n",
        "      - StandardScaler:Centers the data (mean = 0) and scales it (standard deviation = 1).\n",
        "      - *Best for algorithms sensitive to distribution like Logistic Regression, SVM.*\n",
        "      ```\n",
        "      from sklearn.preprocessing import StandardScaler\n",
        "      scaler = StandardScaler()\n",
        "      X_scaled = scaler.fit_transform(X)\n",
        "      ```\n",
        "    - MinMax Scalar: Scales features to a fixed range (usually 0-1)\n",
        "    - *Useful when features need bounded scaling for neural networks or interpretable output.*\n",
        "\n",
        "      ```\n",
        "      from sklearn.preprocessing import MinMaxScaler\n",
        "      scaler = MinMaxScaler()\n",
        "      X_scaled = scaler.fit_transform(X)\n",
        "      ```\n",
        "\n",
        "23. What is sklearn.preprocessing? - duplicate\n",
        "  ## - Duplicate, Answered Above -\n",
        "\n",
        "24. How do we split data for model fitting (training and testing) in Python? - duplicate\n",
        "  ## - Duplicate, Answered Above -\n",
        "\n",
        "25. Explain data encoding?\n",
        "  - It's a preprocessing step to convert categorical values into a numerical format that ML models can understand.\n",
        "  - Common Techniques:\n",
        "\n",
        "|Method|Description|Example|\n",
        "|:----:|:----:|:----:|\n",
        "|Label Encoding|Assigns each category a Unique number|{'cat':0, 'dog':1}|\n",
        "|One Hot Encoding|Creates separate binary columns for each category|cat-> [1,0], dog -> [0]|\n",
        "\n",
        "      ```\n",
        "      import pandas as pd\n",
        "      pd.get_dummies(df['color'])  # One-Hot Encoding\n",
        "      ```\n"
      ],
      "metadata": {
        "id": "-XTNHm7Pmxov"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PS-9u9FNMTqb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}